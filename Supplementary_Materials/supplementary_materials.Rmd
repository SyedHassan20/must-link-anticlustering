---
title: "Supplementary materials to TITLE"
author: "Martin Papenberg"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
bibliography: lit.bib
---

```{r include = FALSE}
# Set some knitr options
library(knitr)
library(anticlust)
library(here)
library(tidyverse)
library(patchwork)
opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", echo = FALSE)

tt <- read.csv(here("Application", "sample_data.csv"))
N <- nrow(tt)

numeric_features <- tt[, c("age", "BMI")]
categorical_features <- tt[, c("race", "ethnicity", "clinical_site", 
       "anatomical_site", "disease_stage", "cycle_phase", "sample_type", "lesion_type")]

```

## Standard algorithm for anticlustering

To assign samples to batches, we use anticlustering. Anticlustering is an optimization method that is characterized by (a) an objective function that quantifies the balance among batches, and (b) an algorithm that conducts the batch assignment in such a way that balance among batches is maximized via the objective function. Anticlustering owes its name to the fact that the objective functions it uses are the reversal of criteria used in cluster analysis. For example, @spath1986 already recognized that by maximizing instead of minimizing the k-means criterion (the "variance"), he was able to create groups that are similar to each other, and presented it as an improvement over the more intuitive random assignment. 

In our application, we optimize the (a) diversity objective using (b) the exchange algorithm by @papenberg2020. This constellation of objective and algorithm is also the default method implemented in the R package `anticlust` [@R-anticlust]. The diversity is defined as the total sum the within-cluster sums of dissimilarities [@brusco2019]. When assigning samples in such a way that the diversity is maximized, we simultaneously maximize similarity between batches. @papenberg2020 referred to the maximization of the diversity as "anticluster editing" because the minimization of the diversity is also well-known from the area of cluster analysis---under the term "cluster editing" [@shamir2004vf; @bocker2011]. 

The anticlustering exchange algorithm takes as input (1) a distance matrix, quantifying the pairwise dissimilarity among samples, and (2) the number of batches $K$. As measure of dissimilarity, we use the common Euclidean distance, which transfers the features of our samples to pairwise distances. It is defined as 

$$
d(x, y) =  \sqrt{\sum\limits_{i = 1}^{M}(x_i - y_i)^2}
$$

where $M$ is the number of numeric features describing two samples $x$ = ($x_1, \ldots, x_M$) and $y$ = ($y_1, \ldots, y_M$). When samples are described by two features, the Euclidean distance corresponds to the geometric, "straightline" distance between two points in a two-dimensional space; more similar data points are closer to each other. Figure&nbsp;1 illustrates the computation of the Euclidean distance and the diversity for the numeric features BMI and age that were used in our motivating application. For categorical variables, we use binary coding before including them in the computation of the Euclidean distance. Table 1 illustrates binary coding for the feature race in our data set, which had five unique values: `r paste0("(", letters[1:5], ") ", unique(tt$race))`. Such a categorical variable can be recoded into four binary variables to maintain the information included in the original variable. 

```{r, fig.width = 6, fig.height = 6, fig.cap = "Illustrates the conversion from numeric features to Euclidean distance, and (anti)clustering assignments based on minimum and maximum diversity using the Euclidean distance. Panel A illustrates the BMI and age of twelve women in our synthetic data in a scatter plot. Panel B represents the Euclidean distances between features as a straight line in the two-dimensional space. The Euclidean distance is proportional to the length of the connecting lines in panel B. Panel C illustrates a clustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{minimum} diversity. Panel D illustrates an anticlustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{maximum} diversity. The diversity is computed as the sum of within-(anti)cluster distances, which are highlighted in Panel C and Panel D through connecting lines."}

# Select 12 points ("arbitrarily")       
not_duplicated <- !duplicated(numeric_features)
six_randos <- c(28L, 144L, 108L, 102L, 7L, 138L, 54L, 147L, 1L, 87L, 110L, 31L)
points <- numeric_features[not_duplicated, ][six_randos, ]


## GENERATE FIGURE 1
standard <- c(5, 4, 4, 2) + 0.1
par(mfrow = c(2, 2))
size_letter <- 1.5

### A
par(mar = c(0, standard[2], standard[3], 0))
plot(points, las = 1, xaxt = "n", xlab = "")
legend("topleft", title = "A", bty = "n", legend = "", title.cex = size_letter)

### B
par(mar = c(0, 0, standard[3], standard[4]))
plot(points, las = 1, xaxt = "n", yaxt = "n")
anticlust:::draw_clique(
  points[,1], points[,2], col = "black",
  lwd = .7, lty = 2)
legend("topleft", title = "B", bty = "n", legend = "", title.cex = size_letter)

### C
par(mar = c(standard[1], standard[2], 0, 0))
clusters <- balanced_clustering(points, K = 3, method = "ilp")
colors <- c("#a9a9a9", "#df536b", "#61d04f")
cex <-  c(0.7, 1.2, 1.5)
pch <- c(19, 15, 17)

# Plot the data while visualizing the different clusters
plot(
  points,
  col = colors[clusters],
  pch = pch[clusters],
  cex = cex[clusters],
  las = 1, xlab = "Age"
)
legend("topleft", title = "C", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = clusters, 
  cols = colors[clusters], 
  lty = 2, lwd = .5
)


### D
par(mar = c(standard[1], 0, 0, standard[4]))

anticlusters <- anticlustering(points, K = 3, method = "ilp")
plot(
  points,
  col = colors[anticlusters],
  pch = pch[anticlusters],
  yaxt = "n", xlab = "Age"
)
legend("topleft", title = "D", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = anticlusters, 
  cols = colors[anticlusters], 
  lty = 2, 
  lwd = .7
)


```

```{r}
Race <- categorical_features[not_duplicated, c("race")][six_randos]
Race[grepl("Pacific Islander", Race)] <- "Pacific Islander"

mat <-  cbind(Race, categories_to_binary(Race))
rownames(mat) <- mat[,1]
knitr::kable(
  mat[!duplicated(mat), -1], 
  col.names = gsub("categories", "", colnames(mat)), 
  caption = "Illustrate the recoding of the variable Race using four binary variables."
)
```

The exchange algorithm that maximizes the diversity consists of two steps: an initialization step and an optimization step. As initialization, it randomly assigns samples to $K$ equal-sized batches. In principle, unequal-sized batches would also be possible with our algorithm, but equal-sized batches were required in the current application. After initialization, the algorithm selects the first sample and checks how the diversity would change if the sample were swapped with each sample that is currently assigned to a different batch. After simulating each exchange---that is $N - \frac{N}{K}$ exchanges---it realizes the one exchange that increases the diversity the most. It does not conduct an exchange if no improvement in diversity is possible. This procedure is repeated for each sample, leading to the evaluation of $N \cdot \frac{N}{K}$ exchanges in total; it terminates after the last sample was processed. The procedure might also restart at the first element and reiterate through all samples until no exchange leads to an improvement any more, i.e., until a local maximum is found. In `anticlust`, we also implemented this local maximum search, which corresponds to the algorithm LCW by @weitz1998. For better results, it is also possible to restart the search algorithm multiple times using different (random) initializations [@spath1986]. 

## Including must-link constraints with anticlustering

```{r}
must_link_frequencies <- table(table(tt$patientID))
```

In our application, samples belonging to the same patient were required to be assigned to the same batch; we refer to a set of samples that must be assigned to same batch as a *must-link group*. For the data set that resembled our actual application, we simulated `r nrow(tt)` samples from `r length(unique(tt$patientID))` unique patients. Most patients (*n* = `r must_link_frequencies[1]`) were included with 1 sample. The remaining `r nrow(tt) - must_link_frequencies[1]` patients were part of a must-link group, with group sizes varying between 2 (`r must_link_frequencies[2]` must-link groups of size 2) and 8 (`r must_link_frequencies[7]` must-link group of size 8). 

To include must-link constraints with anticlustering, we use a downscaled data set where each patient constitutes a single unit in the anticlustering process. Some adjustments are of the exchange method are required to ensure that despite using a reduced data set (a) we still obtain a valid partitioning regarding the size constraints (equal-sized batches) and (b) that the diversity is computed correctly during optimization. We therefore adjusted both the initialization phase as well as the optimization phase of the exchange algorithm. During initialization, we assign all patients that are part of a must-link cluster in a first step. Each of these patients must has to be assigned to one of the $K$ batches without exceeding the maximum capacity of each batch. Using this conceptualization, the initialization step corresponds to a bin packing problem: We assign a weight to each patient, corresponding to the number of samples she provided. There are $K$ batches ("bins") with a capacity $\frac{N}{K}$, which have to be filled with patients while the sum of weights is not allowed to exceed the capacity. Bin packing is one the classical NP complete problem in computer science [@garey1979] and many optimal and heuristic algorithms have been developed to address it. We use a randomized fit heuristic to fill the batches: For each must-link cluster, we iterate through the $K$ batches in random order and assign it to the first batch where it fits. The process is expected to evenly distribute the must-link clusters among batches, and the random component is particularly useful if we use multiple restarts for the exchange algorithm. After assigning the must-link clusters to batches, the remaining samples can be assigned randomly to fill the remaining space. Note that our randomized fit algorithm is a heuristic that may not find an assignment of must-link groups to batches, even if one is theoretically available. If the heuristic indicates that the batches do cannot hold the must-link clusters, we therefore use an optimal algorithm based on integer linear programming as fallback option to verify if the constraints really cannot be fulfilled [citation].

The optimization phase of the exchange algorithm also uses the downscaled data set where each must-link group corresponds to a single unit of analysis. For example, in our application, the original data set consisted of `r nrow(tt)` samples, but the optimization algorithm works on a data set of `r length(unique(tt$PatientID))` unique patients. To obtain the reduced distance matrix that preserves all information of the original distance matrix, we can sum all pairwise distances between elements in different must-link clusters [@bocker2011]. This transformation preserves the computation of the diversity as compared to using the full data set. The exchange heuristic is then conducted on the merged elements. During the exchange process, we only exchange must-link clusters of the same size to ensure that the cardinality constraints are still respected in the end (i.e., equal-sized groups).

## Simulation Study


```{r}
tt <- read.csv(here("Simulation_vs_OSAT", "results.csv"), sep = ";")
tt$ID <- 1:nrow(tt)
p_values <- tt[, grepl("p_", colnames(tt))]

# global results OSAT vs. anticlust. How often is p value of anticlust better (i.e. larger)?
anticlust_better <- apply(p_values, 1, function(x) x[1:5] < x[6:10])
osat_better <- apply(p_values, 1, function(x) x[1:5] > x[6:10])
same <- apply(p_values, 1, function(x) x[1:5] == x[6:10])

anticlust_better_percent <- round(mean(anticlust_better, na.rm = TRUE) * 100)
osat_better_percent <- round(mean(osat_better, na.rm = TRUE) * 100)
same_percent <- round(mean(same, na.rm = TRUE) * 100)

avg_constrained_obj <- round(mean(tt$diversity_constrained / tt$diversity_unconstrained) * 100, 1)
constrained_not_worse <- round(mean(apply(p_values, 1, function(x) x[6:10] <= x[11:15]), na.rm = TRUE)*100)

```


We conducted a simulation study to illustrate the usefulness of anticlustering for batch assignment. The simulation followed two goals. First, it compared anticlustering with the OSAT package, which is currently the gold standard for automated batch assignment (citation). Second, it investigated whether the quality of batch assignment is reduced with must-link constraints as compared to an unconstrained assignment. We generated `r nrow(tt)` data sets, which were all processed via (a) the default OSAT algorithm (optimal shuffle with 5000 repetitions), (b) unconstrained anticlustering and (c) anticlustering subject to must-link constraints. In each data set, we randomly determined the number of categorical variables (2-5), the number of classes per variable (2-5), the total sample size (between 50 and 500) and the number of batches (2, 5, or 10 equal-sized batches). Must-link constraints were randomly generated in such a way that the distribution of constraints resembled our motivating application: 58% of all elements had no must-link partner; 29% had 1 must-link partner; 10% had 2 must-link partners, and 3% had 3 or more must-link partners. The code and data to reproduce the simulation and analysis is openly available via XXX (**TODO**). 

For each simulation run, we computed $\chi^2$-tests to assess the imbalance among batches for each of the 2-5 variables, for each of the three competing methods. We stored the *p* value associated with each test. A higher *p* value indicates that there is less imbalance among batches, i.e., that the batches are more similar. The simulation revealed that in `r anticlust_better_percent`% of all variable comparisons, balance among batches was better when using anticlustering as compared to OSAT. Balance was equal in `r same_percent`% of all comparisons, and only in `r osat_better_percent`% OSAT outperformed anticlust. These results clearly underline the power of anticlustering for batch assignment. Moreover, the anticlustering assignment that was subjected to must-link constraints on average achieved `r avg_constrained_obj`% of the objective value of the unconstrained assignment. Hence, must-link constraints are not only desirable from a user's point of view, but they also do not decrease batch balance considerably; in `r constrained_not_worse`% of all cases, balance was not at all reduced by the constraints. Figure 2 illustrates the average balance among batches in dependence of the factors that varied between data sets. Must-link constraints primarily reduced balance in smaller data sets, but did not strongly affect the balance in larger data sets. Remarkably, the constrained anticlustering assignment led to better balance than the OSAT assignment that did not employ any constraints. Figure 2 also shows that for anticlustering, balance was not reduced when the number of variables increased, which however posed a more severe challenge for OSAT.

```{r, fig.cap= "Average p values in dependence of the factors that varied in the simulation study. Higher p values indicate better balance. Anticlustering maintained a comparable level of balance in all conditions. OSAT's performance decreased with increasing number of variables and number of categories per variable."}

## Some more sophisticated analyes:
dfl <- tt |> 
  select(ID, N, M, K, P, starts_with("p")) |> 
  pivot_longer(
    cols = starts_with("p_")
  ) |> 
  na.omit()

dfl$Method <- "Anticlustering"
dfl$Method[grepl("osat", dfl$name)] <- "OSAT"
dfl$Method[grepl("p_anticlust_c", dfl$name)] <- "Must-Link Anticlustering"

dfl$N_category <- santoku::chop(dfl$N, breaks = c(100, 200, 300, 400))
dfl$K <- ordered(dfl$K)
dfl$M <- ordered(dfl$M)
dfl$P <- ordered(dfl$P)

p0 <- dfl |> 
  group_by(Method, N_category) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = N_category, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  geom_line(aes(color = Method, linetype = Method)) +
  theme_bw(base_size = 8) +
  xlab("Sample size (categorized)") +
  ylab("Average p value")

p1 <- dfl |> 
  group_by(Method, M) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = M, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  geom_line(aes(color = Method, linetype = Method)) +
  theme_bw(base_size = 8) +
  xlab("Number of variables") +
  ylab("")

p2 <- dfl |> 
  group_by(Method, K) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = K, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  geom_line(aes(color = Method, linetype = Method)) +
  theme_bw(base_size = 8) +
  xlab("Number of batches") +
  ylab("Average p value")

p3 <- dfl |> 
  group_by(Method, P) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = P, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  geom_line(aes(color = Method, linetype = Method)) +
  theme_bw(base_size = 8) +
  xlab("Number of categories per variable") +
  ylab("")

p0 + p1 + p2 + p3+ plot_layout(guides = "collect", widths = c(2, 1)) 
```

## Optimal algorithm for anticlustering under cannot-link constraints

- Solving anticlustering optimally (i.e., finding a batch assignment with globally optimal value in diversity) under must-link constraints is possible using the ILP by @papenberg2020
- We have to adjust the input matrix: Samples that must be linked receive sufficiently large pairwise distance; in this case, a globally optimal solution must pair these samples in the same batch (if the constraints can be fulfilled at all)
- We investigate the feasibiliy of the optimal approach, which solves a computationally difficult (NP hard) problem (it seems to scale to about 40-50 samples; for larger data sets, a heuristic is required)
- We can use the optimal algorithm to validate the quality of our heuristic (how often does it find the globally optimal solution)

## References
