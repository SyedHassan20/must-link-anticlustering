---
title: "Supplementary materials to TITLE"
author: "Martin Papenberg"
output:
  pdf_document: default
bibliography: lit.bib
---

```{r include = FALSE}
# Set some knitr options
library(knitr)
library(anticlust)
library(here)
library(tidyverse)
library(patchwork)
library(kableExtra)
opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", echo = FALSE)

df <- read.csv(here("Application", "sample_data.csv"))
N <- nrow(df)

numeric_features <- df[, c("age", "BMI")]
categorical_features <- df[, c("race", "ethnicity", "clinical_site", 
       "anatomical_site", "disease_stage", "cycle_phase", "sample_type", "lesion_type")]

```

## Design

### Motivating Example

```{r}
must_link_frequencies <- table(table(df$patientID))
N_unique <- length(unique(df$patientID))
```

- Explain the application and why the application / batch assignment is needed
- Explain "real" data set and synthetic data set 
  * which variables are included (why is it relevant to balance them?)
  * (Why we do not share the original data)


```{r}

set.seed(123)

# I just use one of the categorical features for this illustration. 
# Using more variables leads to decreased results for every single variable 
# (of course it is easier to equate one variable than many variables)
kmeans_input <- cbind(numeric_features, categories_to_binary(df$ethnicity)) 
kmeans_input <- scale(kmeans_input) # scaling is usually good

distances <- dist(kmeans_input)^2

nrep <- 10
K <- 16

df$Batch <- anticlustering(
  distances, 
  K = K,
  method = "local-maximum", # method LCW 
  repetitions = nrep
)

df$Batch2 <- anticlustering(
  distances, 
  K = K,
  method = "local-maximum",
  repetitions = nrep,
  must_link = df$patientID
)

df$Random_Batch <- sample(df$Batch)

tab1 <- df |> 
  group_by(Batch) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" =  mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab1$`Mean Age` <- prmisc::force_decimals(tab1$`Mean Age`)
tab1$`Mean BMI` <- prmisc::force_decimals(tab1$`Mean BMI`)

tab2 <- df |> 
  group_by(Batch2) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" = mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab2$`Mean Age` <- prmisc::force_decimals(tab2$`Mean Age`)
tab2$`Mean BMI` <- prmisc::force_decimals(tab2$`Mean BMI`)
tab3 <- df |> 
  group_by(Random_Batch) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" = mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab3$`Mean Age` <- prmisc::force_decimals(tab3$`Mean Age`)
tab3$`Mean BMI` <- prmisc::force_decimals(tab3$`Mean BMI`)

table_caption <- "Balance among 16 batches after implementing three different assignment procedures"

tab <- cbind(Batch = 1:16, cbind(tab1[, -1], tab2[, -1], tab3[, -1]))
tab |>
  kbl(booktabs = TRUE, align = "c", caption = table_caption) |>
  kable_styling(latex_options = c("striped", "scale_down")) |>
  add_header_above(
    c(" " = 1, "Unconstrained Anticlustering" = 3, "Constrained Anticlustering" = 3, "Random Assignment" = 3)
  )
```

The synthetic data set that we generated to resemble our actual application consisted of `r N` samples from `r N_unique` unique patients. Samples belonging to the same patient were required to be assigned to the same batch. Most patients (*n* = `r must_link_frequencies[1]`) were included with 1 sample. The remaining `r N - must_link_frequencies[1]` patients provided more than one sample: 
`r must_link_frequencies[2]` patients provided 2 samples, 
`r must_link_frequencies[3]` patients provided 3 samples, 
`r must_link_frequencies[4]` patients provided 4 samples, 
`r must_link_frequencies[5]` patients provided 5 samples, 
`r must_link_frequencies[6]` patients provided 6 samples, 
and `r must_link_frequencies[7]` patient provided 8 samples.
We required the samples to be assigned to 16 equal-sized batches. As a perfect split was not possible using this constellation, we created 2 batches containing 24 samples and 14 batches containing 23 samples. We strived for balance among the batches with regard to two numeric variables (age, BMI) and several categorical variables (such as ethniciy, desease stage, and cycle phase). Table 1 illustrates the results of three batch assignments using three of the variables (age, BMI, ethnicity) for illustrative purposes. The anticlustering assignments were implemented using the `anticlust` R package, and the code and data to reproduce the assignment can be retrieved via XXX (**TODO**). The first assignment is based on "standard" anticlustering, which ignores the must-link constraints and assumes that all samples can be assigned independently, with the objective of maximum similarity among batches. This unrestricted anticlustering led to the most pronounced balance among the 16 batches: Average age ranged between 
`r paste(range(as.numeric(tab1[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab1[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab1[["% Hispanic"]])), collapse = " and ")`%.
The second assignment implemented the must-link restrictions, ensuring that samples belonging to the same patient were assigned to the same batch, while still optimizing balance via anticlustering. The constrained assignment reduced the overall similarity among batches slightly, but the variables were arguably still rather well balanced: Among the 16 batches, average age ranged between 
`r paste(range(as.numeric(tab2[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab2[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab2[["% Hispanic"]])), collapse = " and ")`%.
The third assignment used completely random allocation of samples to batches. Random assignment is often considered as the intuitive and simple method for allocation when no other method is available. However, it does not necessarily lead to similarity among batches [@yan2012; @papenberg2020]. In this application, random assignment by far led to the worst balance: Average age ranged between 
`r paste(range(as.numeric(tab3[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab3[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab3[["% Hispanic"]])), collapse = " and ")`%.

In the next section, we will explain the methodology of anticlustering that led to the batch assignments illustrated in Table 1. We will reiterate the general anticlustering methodology first, before outlining how we included must-link constraints with anticlustering. The implementation of must-link constraints with anticlustering is a novel contribution of the current paper. 

### Anticlustering

Anticlustering is an optimization method that is characterized by (a) an objective function that quantifies the balance among batches, and (b) an algorithm that conducts the batch assignment in such a way that balance among batches is maximized. Anticlustering owes its name to the fact that the objective functions it uses are the reversal of criteria used in cluster analysis. For example, @spath1986 already recognized that by maximizing instead of minimizing the k-means criterion (the "variance"), he was able to create groups that are similar to each other, and presented it as an improvement over the more intuitive random assignment. @brusco2019 recognized that other objective functions known from cluster analysis can also be implemented in the context of anticlustering. Anticlustering has uses in many research fields including psychology [@brusco2019; @schaper2023], education [@krauss2013; @baker2002], artificial intelligence [@steghofer2013], machine learning [@mauri2023; @rahu2024], network systems [@mohebi2022], and operations research [@gallego2013; @gliesch2021]. However, to the best of our knowledge, anticlustering has not previously been applied for batch assignment in high throughput sequencing.

In our application, we optimized the *diversity* objective to maximize similarity among batches. While the diversity is technically a measure of within-batch heterogeneity, its maximization simultaneously leads to minimal difference between the distribution of the input variables among batches [@feo1990; cf. @papenberg2024]. @papenberg2020 referred to the maximization of the diversity as "anticluster editing" because the minimization of the diversity is also well-known from the area of cluster analysis---under the term "cluster editing" [@shamir2004vf; @bocker2011]. The diversity is computed on the basis of a measure of pairwise dissimilarity among samples. In particular, it is defined as the overall sum of all dissimilarities among samples that are assigned to the same batch [@brusco2019]. Hence, the diversity is not directly computed on the basis of the features of our samples, but instead it relies on a deduced distance measure. In the context of anticlustering, the Euclidean distance is the most common measure that translates features to dissimilarities [@gallego2013; @papenberg2020]. However, using other distance measures such as the squared Euclidean distance is also possible [@brusco2019]. The Euclidean distance is defined as 

$$
d(x, y) =  \sqrt{\sum\limits_{i = 1}^{M}(x_i - y_i)^2}
$$

where $M$ is the number of numeric features describing two samples $x$ = ($x_1, \ldots, x_M$) and $y$ = ($y_1, \ldots, y_M$). When samples are described by two features, the Euclidean distance corresponds to the geometric, "straightline" distance between two points in a two-dimensional space; more similar data points are closer to each other. For categorical variables, we use binary coding before including them in the computation of the Euclidean distance (see Table 2 for an example). Figure&nbsp;1 illustrates the computation of the Euclidean distance and the computation diversity for the numeric features BMI and age that were used in our motivating application. 

An anticlustering algorithm assigns samples to batches in such a way that the objective function---here, the diversity---is maximized. Anticlustering usually employs heuristic optimization algorithms [@yang2022]. While , heuristics generally provide satisfying results in the context of anticlustering [@papenberg2020], they do not guarantee to find the globally best assignment among all possibilities. In principle, enumerating all possible assignments is a valid strategy to obtain an optimal assignment. However, this approach quickly becomes impossible with increasing $N$ due to an exponential growth of the way in which assignments can be conducted [@papenberg2020]. Moreover, because anticlustering problems (with the exception of some special cases) are also NP-hard [@feo1990], there is probably no algorithm that identifies the globally best assignment without considering all possibilities (at least in the worst case). In practice, heuristics are therefore indispensable. However, for smaller data sets, optimal approaches can be feasible. In the appendix, we discuss an optimal algorithm for anticlustering that we extended towards the inclusion of must-link restrictions. Its applicability is limited to about 40-50 samples. In the following, we present an anticlustering heuristic that is generally applicable to large data sets, and outline how we included must-link constraints with this algorithm.

```{r, fig.width = 6, fig.height = 6, fig.cap = "Illustrates the conversion from numeric features to Euclidean distance, and (anti)clustering assignments based on minimum and maximum diversity using the Euclidean distance. Panel A illustrates the BMI and age of twelve women in our synthetic data in a scatter plot. Panel B represents the Euclidean distances between features as a straight line in the two-dimensional space. The Euclidean distance is proportional to the length of the connecting lines in panel B. Panel C illustrates a clustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{minimum} diversity. Panel D illustrates an anticlustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{maximum} diversity. The diversity is computed as the sum of within-(anti)cluster distances, which are highlighted in Panel C and Panel D through connecting lines. Maximizing the diversity simultaneously leads to similar distribution of the input features among batches."}

# Select 12 points ("arbitrarily")       
not_duplicated <- !duplicated(numeric_features)
six_randos <- c(28L, 144L, 108L, 102L, 7L, 138L, 54L, 147L, 1L, 87L, 110L, 31L)
points <- numeric_features[not_duplicated, ][six_randos, ]


## GENERATE FIGURE 1
standard <- c(5, 4, 4, 2) + 0.1
par(mfrow = c(2, 2))
size_letter <- 1.5

### A
par(mar = c(0, standard[2], standard[3], 0))
plot(points, las = 1, xaxt = "n", xlab = "")
legend("topleft", title = "A", bty = "n", legend = "", title.cex = size_letter)

### B
par(mar = c(0, 0, standard[3], standard[4]))
plot(points, las = 1, xaxt = "n", yaxt = "n")
anticlust:::draw_clique(
  points[,1], points[,2], col = "black",
  lwd = .7, lty = 2)
legend("topleft", title = "B", bty = "n", legend = "", title.cex = size_letter)

### C
par(mar = c(standard[1], standard[2], 0, 0))
clusters <- balanced_clustering(points, K = 3, method = "ilp")
colors <- c("#a9a9a9", "#df536b", "#61d04f")
cex <-  c(0.7, 1.2, 1.5)
pch <- c(19, 15, 17)

# Plot the data while visualizing the different clusters
plot(
  points,
  col = colors[clusters],
  pch = pch[clusters],
  cex = cex[clusters],
  las = 1, xlab = "Age"
)
legend("topleft", title = "C", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = clusters, 
  cols = colors[clusters], 
  lty = 2, lwd = .5
)


### D
par(mar = c(standard[1], 0, 0, standard[4]))

anticlusters <- anticlustering(points, K = 3, method = "ilp")
plot(
  points,
  col = colors[anticlusters],
  pch = pch[anticlusters],
  yaxt = "n", xlab = "Age"
)
legend("topleft", title = "D", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = anticlusters, 
  cols = colors[anticlusters], 
  lty = 2, 
  lwd = .7
)


```

```{r}
Race <- categorical_features[not_duplicated, c("race")][six_randos]
Race[grepl("Pacific Islander", Race)] <- "Pacific Islander"

mat <-  cbind(Race, categories_to_binary(Race))
rownames(mat) <- mat[,1]
knitr::kable(
  mat[!duplicated(mat), -1], 
  col.names = gsub("categories", "", colnames(mat)), 
  caption = "Illustrates the recoding of the categorical variable Race using four binary variables."
)
```

We use an exchange algorithm to maximize the diversity [@spath1986; @papenberg2020; @weitz1998.]. It consists of two steps: an initialization step and an optimization step. As initialization, it randomly assigns samples to $K$ equal-sized batches. In principle, unequal-sized batches would also be possible, but equal-sized batches were required in the current application. After initialization, the algorithm selects the first sample and checks how the diversity would change if the sample were swapped with each sample that is currently assigned to a different batch. After simulating each exchange---that is $N - \frac{N}{K}$ exchanges---it realizes the one exchange that increases the diversity the most. It does not conduct an exchange if no improvement in diversity is possible. This procedure is repeated for each sample, leading to the evaluation of $N \cdot \frac{N}{K}$ exchanges in total; it terminates after the last sample was processed. The procedure might also restart at the first element and reiterate through all samples until no exchange leads to an improvement any more, i.e., until a local maximum is found. In `anticlust`, we also implemented this local maximum search, which corresponds to the algorithm LCW by @weitz1998. For better results, it is also possible to restart the search algorithm multiple times using different (random) initializations [@spath1986]. For the anticlustering assignment illustrated in Table 1, we used `r nrep` repetitions of the local maximum search LCW, with the squared Euclidean distance as measure of pairwise dissimilarity. To ensure comparable weight of the three features, we also applied a standardization of the input variables before the distance was computed, which is recommended if the variables differ strongly in their ranges [@papenberg2024].

## Including Must-Link Constraints with Anticlustering

In our application, samples belonging to the same patient were required to be assigned to the same batch. We refer to a set of samples that must be assigned to same batch as a must-link *clique*. In our application, not all samples were part of a clique. For the synthetic data set that resembled our actual application, we simulated `r N` samples from `r N_unique` unique patients. To include the must-link constraints with anticlustering, we basically use a downscaled data set where each unique patient---but not each single sample---constitutes a unit in the anticlustering process. Hence, in our application, the effective sample size was `r N_unique` instead of `r N`. Some adjustments of the exchange method are required to ensure (a) we still obtain a valid partitioning regarding the size constraints (equal-sized batches) and (b) the diversity is computed correctly during optimization. We therefore had to adjust both the initialization phase as well as the optimization phase of the exchange algorithm. 

During initialization, we first assign all samples to a batch that are part of a clique (`r N - must_link_frequencies[1]` samples). Each clique must be assigned completely to one of the $K$ batches and samples within a clique must not be split apart. At the same time, the maximum capacity of each batch must not be exceeded. Using this conceptualization, the initialization step corresponds to a bin packing problem, which is one the classical NP complete problem in computer science [@garey1979]. That is, we assign a weight to each clique, corresponding to the number of samples it contains. When filling batches, the sum of the weights of the cliques in each batch must not exceed its capacity. Many optimal and heuristic algorithms have been developed to address such a bin packing problem. As the default method, we use a randomized fit heuristic to fill batches. For each must-link clique, we iterate through the $K$ batches in random order and assign it to the first batch where it fits. The process is expected to evenly distribute the must-link cliques among batches, and the random component is particularly useful if we use multiple restarts for the exchange algorithm. After assigning the must-link cliques to batches, the remaining samples can be assigned randomly to fill the remaining space. Note that our randomized fit algorithm is a heuristic that may not find an assignment of must-link groups to batches even if one is theoretically available. If the heuristic indicates that the batches cannot hold the must-link groups, we therefore use an optimal algorithm based on integer linear programming as fallback option, which allows us to verify if the constraints really cannot be fulfilled [@martello1990]. We include the details of this model in the supplementary materials.
 
The optimization phase of the exchange algorithm also uses a downscaled data set where each patient rather than each sample corresponds corresponds to a unit of analysis. To obtain a reduced distance matrix that preserves all information of the original distance matrix, we sum up all pairwise distances between samples in different cliques [@bocker2011]. In the context of maximizing the diversity, this transformation sufficiently preserves the relevant information in the original distance matrix. Using the initial assignment and the reduced distance matrix, we apply the same exchange algorithm as we described for the unrestricted anticlustering application. However, during the exchange process, we only exchange cliques of the same size (e.g., patients providing the same number of samples) to ensure that the cardinality constraints are respected throughout (i.e., equal-sized groups).

## Evaluation

We evaluated the usefulness of anticlustering by comparing it to two alternative approaches for batch assignment: (1) the OSAT method by @yan2012, which already has been used frequently for the purpose of batch assignment, and (2) propensity score batch assignment (PSBA) by @carry2023, which is a more recent method that has not yet been applied frequently. The code and data for all evaluations is openly retrievable from XXX (**TODO**). As first evaluation, we seize up on the example applications that were provided by @yan2012 and @carry2023 to illustrate the usage of OSAT and PSBA, respectively. In each case, we illustrate how anticlustering performs on the example data sets provided by the authors of the alternative methods. It should be noted that neither package implements the must-link restrictions that we provide, so this evaluation is limited to the case of unrestricted assignment. As a second evaluation, we conducted a large scale simulation study that compared anticlustering with OSAT and PSBA using 10,000 synthetic data sets. As a secondary contribution of the simulation study, we investigated whether the quality of batch assignment is reduced when must-link constraints are included with anticlustering, as compared to an unconstrained anticlustering assignment.

### Implementation of methods

To obtain the most fair comparison to the alternative approaches, anticlustering was implemented using the default settings of the `anticlust` package [package version, @papenberg2020]: We optimized the diversity objective using the (non-local maximum) exchange method without additional repetitions, using the Euclidean distance as measure of dissimilarity. We used the OSAT implementation that is freely available as an R package from Bioconductor [version; citation]. We used the default OSAT algorithm optimal shuffle. **TODO say something about the algorithm**. We increased the number of random initializations to 5000, which is recommended in the vignette that accompanies the OSAT package. @carry2023 provided an R implementation of PSBA that is available from an accompanying online repository.[^github] In the original publication, the authors presented a version of PSBA that investigates all possible batch assignments and selects the one that minimizes discrepancy in propensity scores among batches. However, investigating all possible assignment is only feasible for small data sets and therefore not generally applicable. In the online repository, the authors therefore included an implementation that randomly generates a user defined number of batch assignments, and selects the best one among them. For comparability with OSAT, we set the number of random assignments to 5000. When generating the assignments, PSBA allows to treat one variable a stratification variable; if requested by the user, PSBA only generates assignments that have a perfect split according to the stratification variable. In the simulation, we did not declare a variable as stratification variable, because there is no obvious prioritization for any one variable in synthetic data sets. Moreover, the PSBA implementation provided by the authors only allows stratification variables that contain two levels, which was too limiting for the settings of our simulation. 

[^github]: https://github.com/carryp/PS-Batch-Effect


### Example applications

Alongside the OSAT package, the authors included a vignette that illustrates the basic usage of the OSAT method on an example data set. The data set includes features of 576 persons who provided gene expression samples. In their application, the samples had to be assigned to 6 equal-sized batches, while they attempted to balance age, race and sample type (case vs. control). As the OSAT method does not deal with numeric variables, age was treated as a categorical variable with the levels (0,30], (30,40], (40,50], (50,60], and (60,100]. For their evaluation, the authors conducted the OSAT assignment and then computed a $\chi^2$-test that quantifies imbalance among batches for each of the 3 variables. A larger *p*-value associated with the $\chi^2$-test indicates that the distribution of the variables is more similar among batches. The authors reported *p*-values of .99058 for sample type,  .99963 for race, and 1.00000 for age group. Anticlustering led to *p*-values of .99999 for sample type, .99998 for race, and 1.00000 for age group. Hence, in this example provided by the OSAT authors, anticlustering led to improved balance among the six batches compared to OSAT.

The developers of PSBA also provided an example application in a vignette. The application uses the data set GSE122288 from the GEO data base[^GEO]. The data set includes 61 cases who provided blood samples to measure DNA methylation levels. In the hypothetical application, these samples had to be assigned to three batches, two batches containing 20 samples and one batch containing 21 samples. They used PSBA to balance the covariates neonate sex, birth weight, and gestational age, and employed the R package `table1` (citation) to illustrate the balancing. Table 3 reproduces the results and also includes the balance that was obtained via the application of anticlustering. As shown, both approaches led to a similar level of balance in this example. 

[^GEO]: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE122288


```{r}

t1 <- read.csv("Results_GSE122288_Propensity_Score.csv", sep = ";")[, -5] 
t2 <- read.csv("Results_GSE122288_Anticlust.csv", sep = ";")[-1, -5]
t3 <- rbind(t1, t2)
colnames(t3) <- c("", "B1", "B2", "B3")

kbl(t3, caption = "Comparison of the Propensity score approach and anticlustering.", booktabs = T, row.names=FALSE, align = c("l", "c", "c", "c")) |>
  kable_styling() |>
  pack_rows("Propensity Score", 2, 10) |>
  pack_rows("Anticlustering", 11, 19) |>
  add_indent(c(3:4, 6:7, 9:10, 12:13, 15:16, 18:19))

```

### Simulation Study

```{r}
tt <- read.csv(here("Simulation_vs_OSAT", "results.csv"), sep = ";")
tt$ID <- 1:nrow(tt)
p_values <- tt[, grepl("p_", colnames(tt))]

# global results OSAT vs. anticlust. How often is p value of anticlust better (i.e. larger)?
anticlust_better1 <- apply(p_values, 1, function(x) x[1:5] < x[6:10])
osat_better <- apply(p_values, 1, function(x) x[1:5] > x[6:10])
same1 <- apply(p_values, 1, function(x) x[1:5] == x[6:10])

anticlust_better_percent1 <- round(mean(anticlust_better1, na.rm = TRUE) * 100)
osat_better_percent <- round(mean(osat_better, na.rm = TRUE) * 100)
same_percent1 <- round(mean(same1, na.rm = TRUE) * 100)

# global results PS vs. anticlust. How often is p value of anticlust better (i.e. larger)?
anticlust_better2 <- apply(p_values, 1, function(x) x[1:5] < x[16:20])
ps_better <- apply(p_values, 1, function(x) x[1:5] > x[16:20])
same2 <- apply(p_values, 1, function(x) x[1:5] == x[16:20])

anticlust_better_percent2 <- round(mean(anticlust_better2, na.rm = TRUE) * 100)
ps_better_percent <- round(mean(ps_better, na.rm = TRUE)  * 100)
same_percent2 <- round(mean(same2, na.rm = TRUE) * 100)

avg_constrained_obj <- round(mean(tt$diversity_constrained / tt$diversity_unconstrained) * 100, 1)
constrained_not_worse <- round(mean(apply(p_values, 1, function(x) x[6:10] <= x[11:15]), na.rm = TRUE)*100)

```

For the simulation, we generated `r nrow(tt)` data sets. Data sets were processed via (a) OSAT, (b) PSBA, (c) unconstrained anticlustering and (d) anticlustering subject to must-link constraints. Because the OSAT method is only applicable to categorical variables, we used categorical variables in our simulation. For anticlustering and for PSBA, the categorical variables were binary coded before the methods were applied (see Table 2). For each data set, we randomly determined the number of categorical variables (2-5), the number of classes per variable (2-5; the distribution of classes was uniform), the total sample size $N$ (between 50 and 500) and the number of batches $K$ (2, 4, or 10 equal-sized batches). PSBA was only applied for $K = 2$ and $K = 4$ ($n = `r sum(tt[["K"]] < 10)`$ data sets) because the authors' implementation only allows the assignment to a maximum of four batches. Must-link constraints were generating a random integer between 1 and $N$ (with equal probability), and using the resulting numbers as must-link grouping variables. This rule resulted in a distribution of constraints that resembled our motivating application: 58% of all elements had no must-link partner; 29% had 1 must-link partner; 10% had 2 must-link partners, and 3% had 3 or more must-link partners.

For each simulation run, we computed $\chi^2$-tests to assess the imbalance among batches for each of the 2-5 variables, for each of the three competing methods. We stored the *p*-value associated with each test. A higher *p*-value indicates that there is less imbalance among batches, i.e., that the batches are more similar. The simulation revealed that in `r anticlust_better_percent1`% of all variable comparisons, balance among batches was better when using anticlustering as compared to OSAT. Balance was equal in `r same_percent1`% of all comparisons, and only in `r osat_better_percent`% OSAT outperformed `anticlust`. In `r anticlust_better_percent2`% of all variable comparisons, balance was better when using anticlustering as compared to PSBA. Balance was equal in `r same_percent2`% of all comparisons, and in `r ps_better_percent`% PSBA outperformed anticlustering. Figure 2 illustrates the average *p*-values in dependence of the number of variables ($M$) and the number of batches ($K$). The online supplement also includes additional Figures illustrating average *p*-values in dependence of the other factors that varied in the simulation (the sample size $N$ and the number of classes per categorical variables; **TODO**). Figure 2 shows that increasing the number of variables posed severe challenges for OSAT, but hardly affected anticlustering. PSBA also showed decreased performance with an increasing number of variables, but less so than OSAT.

The anticlustering assignment that was subjected to must-link constraints on average achieved `r avg_constrained_obj`% of the objective value of the unconstrained assignment. Hence, must-link constraints are not only desirable from a user's point of view, but they also do not decrease batch balance considerably; in `r constrained_not_worse`% of all cases, balance was not at all reduced by the constraints. Remarkably, the constrained anticlustering assignment led to better balance than the OSAT and PSBA assignments that did not employ any constraints (see Figure 2).

```{r, fig.cap= "Average \\textit{p} values in dependence of the number of batches and the number of variables. Higher \\textit{p} values indicate better balance. Anticlustering maintained a comparable level of balance in all conditions. OSAT's performance decreased with increasing number of variables most strongly."}

## Some more sophisticated analyes:
dfl <- tt |> 
  select(ID, N, M, K, P, starts_with("p")) |> 
  pivot_longer(
    cols = starts_with("p_")
  ) |> 
  filter(!is.na(value))

dfl$Method <- "Anticlustering"
dfl$Method[grepl("osat", dfl$name)] <- "OSAT"
dfl$Method[grepl("p_anticlust_c", dfl$name)] <- "Must-Link Anticlustering"
dfl$Method[grepl("p_ps", dfl$name)] <- "PSBA"

facets <- c(
  `2` = "K = 2",
  `4` = "K = 4",
  `10` = "K = 10"
)

dfl |> 
  group_by(Method, M, K) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = M, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  geom_line(aes(color = Method, linetype = Method)) +
  facet_grid(cols = vars(`K`), labeller = as_labeller(facets))+
  theme_bw(base_size = 12) +
  xlab("Number of variables") +
  ylab("Average p value") + 
  theme(legend.position = "top", legend.title = element_blank())


```

\clearpage

## References
