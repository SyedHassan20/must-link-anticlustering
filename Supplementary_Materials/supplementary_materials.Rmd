---
title: "Supplementary materials to TITLE"
author: "Martin Papenberg"
output:
  pdf_document: default
bibliography: lit.bib
---

```{r include = FALSE}
# Set some knitr options
library(knitr)
library(anticlust)
library(here)
library(tidyverse)
library(patchwork)
library(kableExtra)
opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", echo = FALSE)

df <- read.csv(here("Application", "sample_data.csv"))
N <- nrow(df)

numeric_features <- df[, c("age", "BMI")]
categorical_features <- df[, c("race", "ethnicity", "clinical_site", 
       "anatomical_site", "disease_stage", "cycle_phase", "sample_type", "lesion_type")]

```

## Design

### Motivating Example

```{r}
must_link_frequencies <- table(table(df$patientID))
N_unique <- length(unique(df$patientID))
```

- Explain the application and why the application / batch assignment is needed
- Explain "real" data set and synthetic data set 
  * which variables are included (why is it relevant to balance them?)
  * (Why we do not share the original data)


```{r}

set.seed(123)

# I just use one of the categorical features for this illustration. 
# Using more variables leads to decreased results for every single variable 
# (of course it is easier to equate one variable than many variables)
kmeans_input <- cbind(numeric_features, categories_to_binary(df$ethnicity)) 
kmeans_input <- scale(kmeans_input) # scaling is usually good

distances <- dist(kmeans_input)^2

nrep <- 10
K <- 16

df$Batch <- anticlustering(
  distances, 
  K = K,
  method = "local-maximum", # method LCW 
  repetitions = nrep
)

df$Batch2 <- anticlustering(
  distances, 
  K = K,
  method = "local-maximum",
  repetitions = nrep,
  must_link = df$patientID
)

df$Random_Batch <- sample(df$Batch)

tab1 <- df |> 
  group_by(Batch) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" =  mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab1$`Mean Age` <- prmisc::force_decimals(tab1$`Mean Age`)
tab1$`Mean BMI` <- prmisc::force_decimals(tab1$`Mean BMI`)

tab2 <- df |> 
  group_by(Batch2) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" = mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab2$`Mean Age` <- prmisc::force_decimals(tab2$`Mean Age`)
tab2$`Mean BMI` <- prmisc::force_decimals(tab2$`Mean BMI`)
tab3 <- df |> 
  group_by(Random_Batch) |> 
  summarise(
    "Mean Age" = mean(age), 
    "Mean BMI" = mean(BMI), 
    "% Hispanic" = mean(ethnicity == "Hispanic or Latino") |> round(2) * 100
  )
tab3$`Mean Age` <- prmisc::force_decimals(tab3$`Mean Age`)
tab3$`Mean BMI` <- prmisc::force_decimals(tab3$`Mean BMI`)

table_caption <- "Balance among 16 batches after implementing three different assignment procedures"

tab <- cbind(Batch = 1:16, cbind(tab1[, -1], tab2[, -1], tab3[, -1]))
tab |>
  kbl(booktabs = TRUE, align = "c", caption = table_caption) |>
  kable_styling(latex_options = c("striped", "scale_down")) |>
  add_header_above(
    c(" " = 1, "Unconstrained Anticlustering" = 3, "Constrained Anticlustering" = 3, "Random Assignment" = 3)
  )
```

The synthetic data set that we generated to resemble our actual application consisted of `r N` samples from `r N_unique` unique patients. Samples belonging to the same patient were required to be assigned to the same batch. Most patients (*n* = `r must_link_frequencies[1]`) were included with 1 sample. The remaining `r N - must_link_frequencies[1]` patients provided more than one sample: 
`r must_link_frequencies[2]` patients provided 2 samples, 
`r must_link_frequencies[3]` patients provided 3 samples, 
`r must_link_frequencies[4]` patients provided 4 samples, 
`r must_link_frequencies[5]` patients provided 5 samples, 
`r must_link_frequencies[6]` patients provided 6 samples, 
and `r must_link_frequencies[7]` patient provided 8 samples.
We required the samples to be assigned to 16 equal-sized batches. As a perfect split was not possible using this constellation, we created 2 batches containing 24 samples and 14 batches containing 23 samples. We strived for balance among the batches with regard to two numeric variables (age, BMI) and several categorical variables (such as ethniciy, desease stage, and cycle phase). Table 1 illustrates the results of three batch assignments using three of the variables (age, BMI, ethnicity) for illustrative purposes. The anticlustering assignments were implemented using the `anticlust` R package, and the code and data to reproduce the assignment can be retrieved via XXX (**TODO**). The first assignment is based on "standard" anticlustering, which ignores the must-link constraints and assumes that all samples can be assigned independently, with the objective of maximum similarity among batches. This unrestricted anticlustering led to the most pronounced balance among the 16 batches: Average age ranged between 
`r paste(range(as.numeric(tab1[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab1[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab1[["% Hispanic"]])), collapse = " and ")`%.
The second assignment implemented the must-link restrictions, ensuring that samples belonging to the same patient were assigned to the same batch, while still optimizing balance via anticlustering. The constrained assignment reduced the overall similarity among batches slightly, but the variables were arguably still rather well balanced: Among the 16 batches, average age ranged between 
`r paste(range(as.numeric(tab2[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab2[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab2[["% Hispanic"]])), collapse = " and ")`%.
The third assignment used completely random allocation of samples to batches. Random assignment is often considered as the intuitive and simple method for allocation when no other method is available. However, it does not necessarily lead to similarity among batches [@yan2012; @papenberg2020]. In this application, random assignment by far led to the worst balance: Average age ranged between 
`r paste(range(as.numeric(tab3[["Mean Age"]])), collapse = " and ")` years, average BMI ranged between 
`r paste(range(as.numeric(tab3[["Mean BMI"]])), collapse = " and ")`, 
and the percentage of samples belonging to hispanic patients ranged between
`r paste(range(as.numeric(tab3[["% Hispanic"]])), collapse = " and ")`%.

In the next section, we will explain the methodology of anticlustering that led to the batch assignments illustrated in Table 1. We will reiterate the general anticlustering methodology first, before outlining how we included must-link constraints with anticlustering. The implementation of must-link constraints with anticlustering is a novel contribution of the current paper. 


### Standard Algorithm for Anticlustering

Anticlustering is an optimization method that is characterized by (a) an objective function that quantifies the balance among batches, and (b) an algorithm that conducts the batch assignment in such a way that balance among batches is maximized. Anticlustering owes its name to the fact that the objective functions it uses are the reversal of criteria used in cluster analysis. For example, @spath1986 already recognized that by maximizing instead of minimizing the k-means criterion (the "variance"), he was able to create groups that are similar to each other, and presented it as an improvement over the more intuitive random assignment. @brusco2019 recognized that other objective functions known from cluster analysis can also be implemented in the context of anticlustering. Anticlustering has uses in many research fields including psychology [@brusco2019; @schaper2023], education [@krauss2013; @baker2002], artificial intelligence [@steghofer2013], machine learning [@mauri2023; @rahu2024], network systems [@mohebi2022], and operations research [@gallego2013; @gliesch2021]. However, to the best of our knowledge, anticlustering has not previously been applied for batch assignment in high throughput sequencing.

In our application, we optimized the (a) diversity objective using (b) the exchange algorithm as discussed by @papenberg2020 [@weitz1998; @papenberg2024]. This constellation of objective and algorithm is also the default method implemented in the R package `anticlust`, which was presented in @papenberg2020. The diversity is computed on the basis of a measure of pairwise dissimilarity among samples. In particular, it is defined as the overall sum of all dissimilarities among samples that are assigned to the same batch [@brusco2019]. Hence, the diversity is not directly computed on the basis of the features of our samples, but instead it relies on a deduced distance measure. In the context of anticlustering, the Euclidean distance is the most common measure that translates features to dissimilarities [@gallego2013; @papenberg2020]. However, using other distance measures such as the squared Euclidean distance is also possible [@brusco2019]. The Euclidean distance is defined as 

$$
d(x, y) =  \sqrt{\sum\limits_{i = 1}^{M}(x_i - y_i)^2}
$$

where $M$ is the number of numeric features describing two samples $x$ = ($x_1, \ldots, x_M$) and $y$ = ($y_1, \ldots, y_M$). When samples are described by two features, the Euclidean distance corresponds to the geometric, "straightline" distance between two points in a two-dimensional space; more similar data points are closer to each other. For categorical variables, we use binary coding before including them in the computation of the Euclidean distance (see Table 2 for an example). Figure&nbsp;1 illustrates the computation of the Euclidean distance and the computation diversity for the numeric features BMI and age that were used in our motivating application. 

An anticlustering algorithm assigns samples to batches in such a way that the objective function---here, the diversity---is maximized. Importantly, maximizing the diversity, which is technically a measure of heterogeneity within batches, simultaneously maximizes similarity among batches, thus leading to a balanced distribution of the input variables among batches [cf. @papenberg2024]. @papenberg2020 referred to the maximization of the diversity as "anticluster editing" because the minimization of the diversity is also well-known from the area of cluster analysis---under the term "cluster editing" [@shamir2004vf; @bocker2011]. 

```{r, fig.width = 6, fig.height = 6, fig.cap = "Illustrates the conversion from numeric features to Euclidean distance, and (anti)clustering assignments based on minimum and maximum diversity using the Euclidean distance. Panel A illustrates the BMI and age of twelve women in our synthetic data in a scatter plot. Panel B represents the Euclidean distances between features as a straight line in the two-dimensional space. The Euclidean distance is proportional to the length of the connecting lines in panel B. Panel C illustrates a clustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{minimum} diversity. Panel D illustrates an anticlustering assignment of the 12 data points to $K = 3$ equal-sized groups via \\textit{maximum} diversity. The diversity is computed as the sum of within-(anti)cluster distances, which are highlighted in Panel C and Panel D through connecting lines. Maximizing the diversity simultaneously leads to similar distribution of the input features among batches."}

# Select 12 points ("arbitrarily")       
not_duplicated <- !duplicated(numeric_features)
six_randos <- c(28L, 144L, 108L, 102L, 7L, 138L, 54L, 147L, 1L, 87L, 110L, 31L)
points <- numeric_features[not_duplicated, ][six_randos, ]


## GENERATE FIGURE 1
standard <- c(5, 4, 4, 2) + 0.1
par(mfrow = c(2, 2))
size_letter <- 1.5

### A
par(mar = c(0, standard[2], standard[3], 0))
plot(points, las = 1, xaxt = "n", xlab = "")
legend("topleft", title = "A", bty = "n", legend = "", title.cex = size_letter)

### B
par(mar = c(0, 0, standard[3], standard[4]))
plot(points, las = 1, xaxt = "n", yaxt = "n")
anticlust:::draw_clique(
  points[,1], points[,2], col = "black",
  lwd = .7, lty = 2)
legend("topleft", title = "B", bty = "n", legend = "", title.cex = size_letter)

### C
par(mar = c(standard[1], standard[2], 0, 0))
clusters <- balanced_clustering(points, K = 3, method = "ilp")
colors <- c("#a9a9a9", "#df536b", "#61d04f")
cex <-  c(0.7, 1.2, 1.5)
pch <- c(19, 15, 17)

# Plot the data while visualizing the different clusters
plot(
  points,
  col = colors[clusters],
  pch = pch[clusters],
  cex = cex[clusters],
  las = 1, xlab = "Age"
)
legend("topleft", title = "C", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = clusters, 
  cols = colors[clusters], 
  lty = 2, lwd = .5
)


### D
par(mar = c(standard[1], 0, 0, standard[4]))

anticlusters <- anticlustering(points, K = 3, method = "ilp")
plot(
  points,
  col = colors[anticlusters],
  pch = pch[anticlusters],
  yaxt = "n", xlab = "Age"
)
legend("topleft", title = "D", bty = "n", legend = "", title.cex = size_letter)
anticlust:::draw_all_cliques(
  points[,1], points[,2], 
  assignment = anticlusters, 
  cols = colors[anticlusters], 
  lty = 2, 
  lwd = .7
)


```

```{r}
Race <- categorical_features[not_duplicated, c("race")][six_randos]
Race[grepl("Pacific Islander", Race)] <- "Pacific Islander"

mat <-  cbind(Race, categories_to_binary(Race))
rownames(mat) <- mat[,1]
knitr::kable(
  mat[!duplicated(mat), -1], 
  col.names = gsub("categories", "", colnames(mat)), 
  caption = "Illustrates the recoding of the categorical variable Race using four binary variables."
)
```

The exchange algorithm that we used to maximize the diversity consists of two steps: an initialization step and an optimization step. As initialization, it randomly assigns samples to $K$ equal-sized batches. In principle, unequal-sized batches would also be possible, but equal-sized batches were required in the current application. After initialization, the algorithm selects the first sample and checks how the diversity would change if the sample were swapped with each sample that is currently assigned to a different batch. After simulating each exchange---that is $N - \frac{N}{K}$ exchanges---it realizes the one exchange that increases the diversity the most. It does not conduct an exchange if no improvement in diversity is possible. This procedure is repeated for each sample, leading to the evaluation of $N \cdot \frac{N}{K}$ exchanges in total; it terminates after the last sample was processed. The procedure might also restart at the first element and reiterate through all samples until no exchange leads to an improvement any more, i.e., until a local maximum is found. In `anticlust`, we also implemented this local maximum search, which corresponds to the algorithm LCW by @weitz1998. For better results, it is also possible to restart the search algorithm multiple times using different (random) initializations [@spath1986]. For the anticlustering assignment illustrated in Table 1, we used `r nrep` repetitions of the local maximum search LCW, with the squared Euclidean distance as measure of pairwise dissimilarity. To ensure comparable weight of the three features, we also applied a standardization of the input variables before the distance was computed [see @papenberg2024].

## Including Must-Link Constraints with Anticlustering

In our application, samples belonging to the same patient were required to be assigned to the same batch. We refer to a set of samples that must be assigned to same batch as a must-link *clique*. In our application, not all samples were part of a clique. For the data set that resembled our actual application, we simulated `r N` samples from `r N_unique` unique patients. To include must-link constraints with anticlustering, we use a downscaled data set where each unique patient---but not each single sample---constitutes a unit in the anticlustering process. Hence, in our application, the effective sample size was `r N_unique` instead of `r N`. Some adjustments of the exchange method are required to ensure (a) we still obtain a valid partitioning regarding the size constraints (equal-sized batches) and (b) the diversity is computed correctly during optimization. We therefore had to adjust both the initialization phase as well as the optimization phase of the exchange algorithm. 

During initialization, we first assign all samples to a batch that are part of a clique (`r N - must_link_frequencies[1]` samples). Each clique must be assigned completely to one of the $K$ batches and samples within a clique must not be split apart. At the same time, the maximum capacity of each batch must not be exceeded. Using this conceptualization, the initialization step corresponds to a bin packing problem, which is one the classical NP complete problem in computer science [@garey1979]. That is, we assign a weight to each clique, corresponding to the number of samples it contains. When filling batches, the sum of the weights of the cliques in each batch must not exceed its capacity. Many optimal and heuristic algorithms have been developed to address such a bin packing problem. As the default method, we use a randomized fit heuristic to fill batches. For each must-link clique, we iterate through the $K$ batches in random order and assign it to the first batch where it fits. The process is expected to evenly distribute the must-link cliques among batches, and the random component is particularly useful if we use multiple restarts for the exchange algorithm. After assigning the must-link cliques to batches, the remaining samples can be assigned randomly to fill the remaining space. Note that our randomized fit algorithm is a heuristic that may not find an assignment of must-link groups to batches even if one is theoretically available. If the heuristic indicates that the batches cannot hold the must-link groups, we therefore use an optimal algorithm based on integer linear programming as fallback option, which allows us to verify if the constraints really cannot be fulfilled [@martello1990]. We include the details of this model in the supplementary materials.
 
The optimization phase of the exchange algorithm also uses a downscaled data set where each patient rather than each sample corresponds corresponds to a unit of analysis. To obtain a reduced distance matrix that preserves all information of the original distance matrix, we sum up all pairwise distances between samples in different cliques [@bocker2011]. In the context of maximizing the diversity, this transformation sufficiently preserves the relevant information in the original distance matrix. Using the initial assignment and the reduced distance matrix, we apply the same exchange algorithm as we described for the unrestricted anticlustering application. However, during the exchange process, we only exchange cliques of the same size (e.g., patients providing the same number of samples) to ensure that the cardinality constraints are respected throughout (i.e., equal-sized groups).

## Evaluation

We provide a twofold evaluation of the usage of anticlustering for batch assignment. The code and data for all evaluations is openly retrievable from XXX (**TODO**). As first evaluation, we seize up on the example applications that were provided by @yan2012 and @carry2023 to illustrate the usage of OSAT and the propensity score method, respectively. In each case, we illustrate how anticlustering performs on the example data sets provided by the authors of the alternative methods. It should be noted that neither package implements the must-link restrictions that we provide, so this evaluation is limited to the case of unrestricted assignment. As a second evaluation, we conducted a large scale simulation study that compares anticlustering with the OSAT package using synthetic data sets. We did not include the propensity score based method by @carry2023 in the simulation, because their current implementation is limited with regard to factors that we deemed important to vary in a large scale assessment. For example, the number of batches their method can process is currently limited to 4, while we also compared the methods' performance using a larger number of batches.

### Comparison with existing approaches

OSAT is freely available as an R package from Bioconductor (citation). Alongside their package, the authors include a vignette that illustrates the basic usage of the OSAT method on an example data set. Their data set includes features of 576 persons who provided gene expression samples. In their application, the samples had to be assigned to 6 equal-sized batches, while they attempted to balance age, race and sample type (case vs. control). As the OSAT method does not deal with numeric variables, age was treated as a categorical variable with the levels (0,30], (30,40], (40,50], (50,60], and (60,100]. For their evaluation, the authors conducted the OSAT assignment and then computed a $\chi^2$-test that quantifies imbalance among batches for each of the 3 variables. A larger *p*-value associated with the $\chi^2$-test indicates that the distribution of the variables is more similar among batches. The authors reported *p*-values of .99058 for sample type,  .99963 for race, and 1.00000 for age group. Anticlustering led to *p*-values of .99999 for sample type, .99998 for race, and 1.00000 for age group. Hence, in this example provided by the OSAT authors, anticlustering led to improved balance among the six batches compared to OSAT.

@carry2023 provided an R implementation of their propensity score method that is available from an accompanying online repository.[^github] Their implementation is also accompanied with a vignette that illustrates the usage of their function on the data set GSE122288 from the GEO data base[^GEO]. The data set includes 61 cases who provided blood samples to measure DNA methylation levels. In their hypothetical application, these samples had to be assigned to three batches, two batches containing 20 samples and one batch containing 21 samples. They used their propensity score method to balance the covariates neonate sex, birth weight, and gestational age. They used the R package `table1` (citation) to illustrate the balancing. Table 3 reproduces the results and also includes the balance that was obtained via the application of anticlustering. As shown, both approaches led to a similar level of balance. 

[^GEO]: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE122288

[^github]: https://github.com/carryp/PS-Batch-Effect

```{r}

t1 <- read.csv("Results_GSE122288_Propensity_Score.csv", sep = ";")[, -5] 
t2 <- read.csv("Results_GSE122288_Anticlust.csv", sep = ";")[-1, -5]
t3 <- rbind(t1, t2)
colnames(t3) <- c("", "B1", "B2", "B3")

kbl(t3, caption = "Comparison of the Propensity score approach and anticlustering.", booktabs = T, row.names=FALSE, align = c("l", "c", "c", "c")) |>
  kable_styling() |>
  pack_rows("Propensity Score", 2, 10) |>
  pack_rows("Anticlustering", 11, 19) |>
  add_indent(c(3:4, 6:7, 9:10, 12:13, 15:16, 18:19))

```

### Simulation Study

```{r}
tt <- read.csv(here("Simulation_vs_OSAT", "results.csv"), sep = ";")
tt$ID <- 1:nrow(tt)
p_values <- tt[, grepl("p_", colnames(tt))]

# global results OSAT vs. anticlust. How often is p value of anticlust better (i.e. larger)?
anticlust_better <- apply(p_values, 1, function(x) x[1:5] < x[6:10])
osat_better <- apply(p_values, 1, function(x) x[1:5] > x[6:10])
same <- apply(p_values, 1, function(x) x[1:5] == x[6:10])

anticlust_better_percent <- round(mean(anticlust_better, na.rm = TRUE) * 100)
osat_better_percent <- round(mean(osat_better, na.rm = TRUE) * 100)
same_percent <- round(mean(same, na.rm = TRUE) * 100)

avg_constrained_obj <- round(mean(tt$diversity_constrained / tt$diversity_unconstrained) * 100, 1)
constrained_not_worse <- round(mean(apply(p_values, 1, function(x) x[6:10] <= x[11:15]), na.rm = TRUE)*100)

```

To more thoroughly evaluate the the usefulness of anticlustering for batch assignment, we conducted a large scale simulation study. The simulation followed two goals. First, it compared anticlustering with the OSAT package, which has been used frequently for the purpose of batch assignment. Second, the simulation study investigated whether the quality of batch assignment is reduced with must-link constraints as compared to an unconstrained assignment. We generated `r nrow(tt)` data sets, which were all processed via (a) the default OSAT algorithm (optimal shuffle with 5000 repetitions), (b) unconstrained anticlustering and (c) anticlustering subject to must-link constraints. To obtain a fair comparison to OSAT, we used the default (non-local maximum) exchange method implemented in `anticlust`, optimizing the diversity on the basis of the Euclidean distance. No additional restarts of the algorithm were conducted and no additional data processing was applied. 

In each data set, we randomly determined the number of categorical variables (2-5), the number of classes per variable (2-5), the total sample size (between 50 and 500) and the number of batches (2, 5, or 10 equal-sized batches). Must-link constraints were randomly generated in such a way that the distribution of constraints resembled our motivating application: 58% of all elements had no must-link partner; 29% had 1 must-link partner; 10% had 2 must-link partners, and 3% had 3 or more must-link partners.

For each simulation run, we computed $\chi^2$-tests to assess the imbalance among batches for each of the 2-5 variables, for each of the three competing methods. We stored the *p* value associated with each test. A higher *p* value indicates that there is less imbalance among batches, i.e., that the batches are more similar. The simulation revealed that in `r anticlust_better_percent`% of all variable comparisons, balance among batches was better when using anticlustering as compared to OSAT. Balance was equal in `r same_percent`% of all comparisons, and only in `r osat_better_percent`% OSAT outperformed `anticlust`. These results clearly underline the power of anticlustering for batch assignment. Moreover, the anticlustering assignment that was subjected to must-link constraints on average achieved `r avg_constrained_obj`% of the objective value of the unconstrained assignment. Hence, must-link constraints are not only desirable from a user's point of view, but they also do not decrease batch balance considerably; in `r constrained_not_worse`% of all cases, balance was not at all reduced by the constraints. Figure 2 illustrates the average balance among batches in dependence of the factors that varied between data sets. Must-link constraints primarily reduced balance in smaller data sets, but did not strongly affect the balance in larger data sets. Remarkably, the constrained anticlustering assignment led to better balance than the OSAT assignment that did not employ any constraints. Figure 2 also shows increasing the number of variables as well as increasing the number of categories per variables posed severe challenges for OSAT, but hardly affected anticlustering.

```{r, fig.cap= "Average \\textit{p} values in dependence of the factors that varied in the simulation study. Higher \\textit{p} values indicate better balance. Anticlustering maintained a comparable level of balance in all conditions. OSAT's performance decreased with increasing number of variables and number of categories per variable."}

## Some more sophisticated analyes:
dfl <- tt |> 
  select(ID, N, M, K, P, starts_with("p")) |> 
  pivot_longer(
    cols = starts_with("p_")
  ) |> 
  na.omit()

dfl$Method <- "Anticlustering"
dfl$Method[grepl("osat", dfl$name)] <- "OSAT"
dfl$Method[grepl("p_anticlust_c", dfl$name)] <- "Must-Link Anticlustering"

dfl$N_category <- santoku::chop(dfl$N, breaks = c(100, 200, 300, 400))
dfl$K <- ordered(dfl$K)
dfl$M <- ordered(dfl$M)
dfl$P <- ordered(dfl$P)

p0 <- dfl |> 
  group_by(Method, N_category) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = N_category, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  theme_bw(base_size = 8) +
  xlab("Sample size (categorized)") +
  ylab("Average p value")

p1 <- dfl |> 
  group_by(Method, M) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = M, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) + 
  theme_bw(base_size = 8) +
  xlab("Number of variables") +
  ylab("")

p2 <- dfl |> 
  group_by(Method, K) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = K, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) +
  theme_bw(base_size = 8) +
  xlab("Number of batches") +
  ylab("Average p value")

p3 <- dfl |> 
  group_by(Method, P) |> 
  summarise(`p value` = mean(value)) |> 
  ggplot(aes(y = `p value`, x = P, color = Method)) +
  geom_point(aes(color = Method, shape = Method)) +
  theme_bw(base_size = 8) +
  xlab("Number of categories per variable") +
  ylab("")

p0 + p1 + p2 + p3+ plot_layout(guides = "collect", widths = c(2, 1)) 
```

## Evaluation

## Optimal algorithm for anticlustering under cannot-link constraints

- Solving anticlustering optimally (i.e., finding a batch assignment with globally optimal value in diversity) under must-link constraints is possible using the ILP by @papenberg2020
- We have to adjust the input matrix: Samples that must be linked receive sufficiently large pairwise distance; in this case, a globally optimal solution must pair these samples in the same batch (if the constraints can be fulfilled at all)
- We investigate the feasibiliy of the optimal approach, which solves a computationally difficult (NP hard) problem (it seems to scale to about 40-50 samples; for larger data sets, a heuristic is required)
- We can use the optimal algorithm to validate the quality of our heuristic (how often does it find the globally optimal solution)

\clearpage

## References
